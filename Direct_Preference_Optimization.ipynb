{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLWRT4rBe1cG",
        "outputId": "d7123eb5-60ca-48b4-95ee-41231e956538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Direct-Preference-Optimization'...\n",
            "remote: Enumerating objects: 310, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 310 (delta 0), reused 1 (delta 0), pack-reused 305 (from 1)\u001b[K\n",
            "Receiving objects: 100% (310/310), 1.04 MiB | 15.68 MiB/s, done.\n",
            "Resolving deltas: 100% (179/179), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Jalalbaim/Direct-Preference-Optimization.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dGvhXr6fCzt",
        "outputId": "27369afe-ac2d-4f1b-ac88-8e4d55a22dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Direct-Preference-Optimization\n"
          ]
        }
      ],
      "source": [
        "cd Direct-Preference-Optimization/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6Y1EgJ2fUgz",
        "outputId": "fb8bde3f-1ddf-4802-dcab-20f495fa38c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From https://github.com/Jalalbaim/Direct-Preference-Optimization\n",
            " * branch            Pierre_summarization -> FETCH_HEAD\n",
            "Branch 'Pierre_summarization' set up to track remote branch 'Pierre_summarization' from 'origin'.\n",
            "Switched to a new branch 'Pierre_summarization'\n"
          ]
        }
      ],
      "source": [
        "!git fetch origin Pierre_summarization\n",
        "!git checkout Pierre_summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmTUVXZ9fyBD",
        "outputId": "25390513-5ddd-46e8-9eb4-ae7a59b9b5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* \u001b[32mPierre_summarization\u001b[m\n",
            "  main\u001b[m\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git branch\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qQYACitef239",
        "outputId": "ac943c0a-b4c8-433d-89cc-d27d3b575b60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cpu)\n",
            "Requirement already satisfied: transformers>=4.40.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.57.3)\n",
            "Collecting datasets==3.6.0 (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.12.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.2.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.6.1)\n",
            "Collecting evaluate>=0.4.0 (from -r requirements.txt (line 14))\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: wandb>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (0.23.1)\n",
            "Collecting protobuf>=3.20.0 (from -r requirements.txt (line 7))\n",
            "  Downloading protobuf-5.28.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting bitsandbytes>=0.39.0 (from -r requirements.txt (line 17))\n",
            "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r requirements.txt (line 2)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r requirements.txt (line 2)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40.0->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30.0->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 11)) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 15)) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 15)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 15)) (4.5.1)\n",
            "INFO: pip is looking at multiple versions of wandb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting wandb>=0.16.0 (from -r requirements.txt (line 15))\n",
            "  Downloading wandb-0.23.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "  Downloading wandb-0.22.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.22.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.22.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.22.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.21.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.21.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "INFO: pip is still looking at multiple versions of wandb to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading wandb-0.21.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.21.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.20.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.20.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading wandb-0.19.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.16.0->-r requirements.txt (line 15))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting wandb>=0.16.0 (from -r requirements.txt (line 15))\n",
            "  Downloading wandb-0.19.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.19.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "  Downloading wandb-0.18.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading wandb-0.18.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading wandb-0.18.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading wandb-0.18.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading wandb-0.18.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "  Downloading wandb-0.18.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "  Downloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 15)) (2.47.0)\n",
            "Collecting setproctitle (from wandb>=0.16.0->-r requirements.txt (line 15))\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.16.0->-r requirements.txt (line 15)) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.0->-r requirements.txt (line 15)) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 3)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 3)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 3)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 3)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.0->-r requirements.txt (line 15)) (5.0.2)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.0-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.17.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Installing collected packages: setproctitle, protobuf, docker-pycreds, wandb, bitsandbytes, datasets, evaluate\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.23.1\n",
            "    Uninstalling wandb-0.23.1:\n",
            "      Successfully uninstalled wandb-0.23.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 5.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.49.0 datasets-3.6.0 docker-pycreds-0.4.0 evaluate-0.4.6 protobuf-5.28.0 setproctitle-1.3.7 wandb-0.17.9\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "a453946cf09249a0967683288da0c030",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E4O8dHmgRym",
        "outputId": "e335379f-8173-4788-edf8-f70e15016971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: CarperAI/openai_summarize_tldr_sft\n",
            "config.json: 1.01kB [00:00, 1.44MB/s]\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 179kB/s]\n",
            "config.json: 100% 665/665 [00:00<00:00, 3.63MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 1.55MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.09MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 2.17MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-02 07:15:43.657304: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-02 07:15:43.662357: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-02 07:15:43.676429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767338143.696783     723 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767338143.702884     723 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767338143.721021     723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338143.721064     723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338143.721069     723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338143.721074     723 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-02 07:15:43.728119: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "pytorch_model.bin.index.json: 25.8kB [00:00, 65.2MB/s]\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "pytorch_model-00003-of-00003.bin:   0% 0.00/4.60G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   0% 0.00/9.78G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   0% 0.00/9.94G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors.index.json: 27.2kB [00:00, 36.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   0% 907k/9.94G [00:02<7:08:53, 386kB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   0% 628k/4.60G [00:02<5:01:16, 255kB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   0% 551k/9.78G [00:02<14:00:04, 194kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   1% 68.0M/9.94G [00:07<16:51, 9.76MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   1% 67.7M/4.60G [00:08<09:13, 8.19MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   1% 135M/9.94G [00:09<09:21, 17.5MB/s] \u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   3% 135M/4.60G [00:09<04:05, 18.2MB/s] \u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   2% 202M/9.94G [00:09<05:36, 28.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   6% 269M/4.60G [00:10<01:43, 41.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   3% 269M/9.94G [00:12<05:56, 27.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:   7% 336M/4.60G [00:12<02:01, 35.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   4% 403M/9.94G [00:12<03:00, 52.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  10% 470M/4.60G [00:13<01:07, 61.1MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   0% 551k/9.78G [00:13<14:00:04, 194kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   5% 470M/9.94G [00:18<06:03, 26.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  13% 604M/4.60G [00:19<01:50, 36.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   5% 537M/9.94G [00:23<07:01, 22.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  16% 738M/4.60G [00:23<01:54, 33.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  18% 805M/4.60G [00:23<01:31, 41.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   6% 604M/9.94G [00:23<05:31, 28.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  19% 873M/4.60G [00:24<01:17, 48.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   7% 673M/9.94G [00:25<04:57, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   0% 1.98M/9.78G [00:29<42:30:33, 63.9kB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  23% 1.07G/4.60G [00:29<01:19, 44.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   8% 807M/9.94G [00:29<04:40, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  25% 1.14G/4.60G [00:30<01:10, 49.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:   9% 941M/9.94G [00:30<03:11, 46.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  26% 1.21G/4.60G [00:30<00:58, 58.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  10% 1.01G/9.94G [00:30<02:43, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  28% 1.27G/4.60G [00:30<00:49, 66.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   1% 69.1M/9.78G [00:31<51:34, 3.14MB/s]   \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.08G/9.94G [00:33<03:19, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  29% 1.34G/4.60G [00:33<01:06, 49.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  11% 1.14G/9.94G [00:33<02:41, 54.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  31% 1.41G/4.60G [00:39<02:03, 25.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  13% 1.28G/9.94G [00:40<04:23, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   1% 69.1M/9.78G [00:43<51:34, 3.14MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  32% 1.48G/4.60G [00:43<02:19, 22.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  14% 1.34G/9.94G [00:44<05:25, 26.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   1% 136M/9.78G [00:45<41:29, 3.87MB/s] \u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  35% 1.61G/4.60G [00:46<01:42, 29.2MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   3% 270M/9.78G [00:47<16:29, 9.61MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  36% 1.68G/4.60G [00:48<01:34, 30.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   4% 404M/9.78G [00:48<09:07, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   6% 606M/9.78G [00:48<04:43, 32.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  15% 1.48G/9.94G [00:49<05:17, 26.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   8% 740M/9.78G [00:51<04:12, 35.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  16% 1.54G/9.94G [00:51<05:17, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  38% 1.75G/4.60G [00:52<01:53, 25.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  17% 1.68G/9.94G [00:52<03:40, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  39% 1.81G/4.60G [00:53<01:31, 30.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:   9% 874M/9.78G [00:53<03:23, 43.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  41% 1.88G/4.60G [00:54<01:15, 36.1MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  10% 1.01G/9.78G [00:54<02:38, 55.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  18% 1.75G/9.94G [00:54<03:29, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  11% 1.08G/9.78G [00:55<02:28, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  19% 1.88G/9.94G [00:55<02:28, 54.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  42% 1.95G/4.60G [00:55<01:08, 38.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  12% 1.14G/9.78G [00:55<02:12, 65.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  44% 2.01G/4.60G [00:57<01:04, 39.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  13% 1.28G/9.78G [00:57<01:54, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  20% 1.95G/9.94G [00:57<02:48, 47.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  21% 2.08G/9.94G [00:58<02:07, 61.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  23% 2.28G/9.94G [00:59<01:32, 82.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  14% 1.34G/9.78G [01:01<03:16, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  24% 2.42G/9.94G [01:01<01:30, 83.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  15% 1.48G/9.78G [01:03<02:44, 50.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.55G/9.94G [01:03<01:32, 80.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  16% 1.54G/9.78G [01:05<03:12, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  26% 2.62G/9.94G [01:06<02:07, 57.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  45% 2.08G/4.60G [01:06<02:25, 17.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  27% 2.68G/9.94G [01:08<02:24, 50.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  17% 1.68G/9.78G [01:10<03:48, 35.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  47% 2.15G/4.60G [01:10<02:30, 16.3MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.81G/9.78G [01:11<02:42, 49.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  51% 2.35G/4.60G [01:11<01:05, 34.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  19% 1.88G/9.78G [01:11<02:19, 56.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  20% 1.95G/9.78G [01:12<02:05, 62.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  52% 2.42G/4.60G [01:12<00:59, 37.0MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  21% 2.08G/9.78G [01:13<01:34, 81.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  55% 2.55G/4.60G [01:13<00:39, 52.4MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  22% 2.15G/9.78G [01:13<01:32, 82.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  58% 2.68G/4.60G [01:16<00:37, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  63% 2.89G/4.60G [01:17<00:22, 75.3MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  23% 2.22G/9.78G [01:17<02:50, 44.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  66% 3.02G/4.60G [01:18<00:19, 80.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  24% 2.35G/9.78G [01:18<02:05, 59.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.75G/9.94G [01:19<06:16, 19.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  67% 3.06G/4.60G [01:19<00:20, 73.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  69% 3.19G/4.60G [01:24<00:30, 46.4MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  25% 2.42G/9.78G [01:24<04:05, 30.0MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  71% 3.26G/4.60G [01:25<00:28, 47.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  27% 2.62G/9.78G [01:28<03:06, 38.5MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  74% 3.40G/4.60G [01:28<00:25, 47.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.69G/9.78G [01:28<02:35, 45.7MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  75% 3.46G/4.60G [01:29<00:21, 52.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  28% 2.76G/9.78G [01:29<02:17, 51.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  77% 3.53G/4.60G [01:30<00:19, 54.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.89G/9.78G [01:30<01:44, 66.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.75G/9.94G [01:33<06:16, 19.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  78% 3.60G/4.60G [01:34<00:29, 33.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  30% 2.96G/9.78G [01:34<02:51, 39.8MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  81% 3.73G/4.60G [01:35<00:16, 51.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  84% 3.86G/4.60G [01:36<00:11, 64.5MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.09G/9.78G [01:37<02:38, 42.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  87% 4.00G/4.60G [01:38<00:09, 64.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  28% 2.82G/9.94G [01:39<13:20, 8.89MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  90% 4.13G/4.60G [01:40<00:06, 71.4MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  32% 3.16G/9.78G [01:40<02:59, 36.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  29% 2.89G/9.94G [01:40<10:18, 11.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  91% 4.20G/4.60G [01:41<00:05, 72.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  30% 2.96G/9.94G [01:41<07:48, 14.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.29G/9.78G [01:41<02:13, 48.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  31% 3.09G/9.94G [01:41<04:33, 25.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  34% 3.36G/9.78G [01:42<01:58, 54.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  35% 3.43G/9.78G [01:42<01:34, 67.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  94% 4.33G/4.60G [01:43<00:03, 70.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  96% 4.40G/4.60G [01:43<00:02, 85.2MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  36% 3.49G/9.78G [01:43<01:37, 64.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.16G/9.94G [01:43<04:13, 26.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  32% 3.22G/9.94G [01:44<03:28, 32.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.36G/9.94G [01:45<02:18, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  37% 3.63G/9.78G [01:45<01:35, 64.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  97% 4.47G/4.60G [01:46<00:02, 47.4MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  38% 3.76G/9.78G [01:46<01:12, 82.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  39% 3.83G/9.78G [01:48<01:33, 63.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  34% 3.42G/9.94G [01:48<02:55, 37.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  40% 3.90G/9.78G [01:49<01:19, 73.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  35% 3.49G/9.94G [01:49<02:24, 44.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  41% 3.96G/9.78G [01:49<01:13, 79.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin:  99% 4.53G/4.60G [01:49<00:01, 36.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  41% 4.03G/9.78G [01:50<01:04, 89.3MB/s]\u001b[A\u001b[A\n",
            "pytorch_model-00003-of-00003.bin: 100% 4.60G/4.60G [01:50<00:00, 41.5MB/s]\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  42% 4.10G/9.78G [01:50<01:01, 92.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  43% 4.17G/9.78G [01:51<00:50, 112MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  36% 3.62G/9.94G [01:51<02:09, 48.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  37% 3.69G/9.94G [01:52<01:57, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  44% 4.30G/9.78G [01:52<00:55, 98.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.76G/9.94G [01:53<01:40, 61.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  45% 4.37G/9.78G [01:53<00:54, 99.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  38% 3.83G/9.94G [01:53<01:30, 67.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  46% 4.50G/9.78G [01:54<00:42, 124MB/s] \u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.57G/9.78G [01:54<00:43, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  39% 3.89G/9.94G [01:55<01:35, 63.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  41% 4.03G/9.94G [01:55<01:01, 95.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  42% 4.16G/9.94G [01:57<01:03, 90.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  47% 4.63G/9.78G [01:57<01:20, 64.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  43% 4.30G/9.94G [01:58<00:53, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  44% 4.37G/9.94G [01:58<00:50, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  48% 4.70G/9.78G [01:58<01:29, 56.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.44G/9.94G [01:59<00:47, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  45% 4.50G/9.94G [01:59<00:43, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  47% 4.64G/9.94G [02:01<00:53, 99.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  48% 4.77G/9.94G [02:01<00:38, 133MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.77G/9.78G [02:02<02:10, 38.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.84G/9.94G [02:03<00:52, 96.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  49% 4.84G/9.78G [02:03<01:59, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  49% 4.91G/9.94G [02:04<00:56, 89.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  50% 4.90G/9.78G [02:04<01:55, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  50% 4.97G/9.94G [02:05<01:02, 79.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  51% 5.04G/9.78G [02:05<01:06, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.04G/9.94G [02:05<00:55, 88.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  52% 5.10G/9.78G [02:06<01:02, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  51% 5.11G/9.94G [02:06<00:49, 96.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  53% 5.17G/9.78G [02:06<01:02, 74.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  52% 5.17G/9.94G [02:07<00:49, 95.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  54% 5.24G/9.78G [02:09<01:32, 49.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.24G/9.94G [02:09<01:26, 54.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  55% 5.37G/9.78G [02:09<00:57, 77.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  53% 5.31G/9.94G [02:10<01:15, 61.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  54% 5.37G/9.94G [02:11<01:19, 57.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  55% 5.51G/9.94G [02:15<01:44, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  57% 5.64G/9.94G [02:16<01:15, 57.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.44G/9.78G [02:21<03:45, 19.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  58% 5.78G/9.94G [02:21<01:41, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  59% 5.84G/9.94G [02:22<01:30, 45.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  60% 5.98G/9.94G [02:23<01:04, 60.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.11G/9.94G [02:23<00:42, 90.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  56% 5.50G/9.78G [02:24<03:35, 19.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  62% 6.18G/9.94G [02:25<00:51, 72.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.64G/9.78G [02:30<03:07, 22.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  58% 5.71G/9.78G [02:30<02:28, 27.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  63% 6.25G/9.94G [02:30<01:46, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  64% 6.38G/9.94G [02:31<01:12, 49.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.51G/9.94G [02:35<01:17, 44.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  59% 5.77G/9.78G [02:36<03:20, 20.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  66% 6.58G/9.94G [02:37<01:18, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  60% 5.84G/9.78G [02:37<02:37, 25.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  67% 6.65G/9.94G [02:37<01:05, 50.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  68% 6.72G/9.94G [02:38<01:00, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  61% 5.97G/9.78G [02:42<02:26, 26.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.04G/9.78G [02:42<01:59, 31.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  69% 6.85G/9.94G [02:43<01:15, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  62% 6.10G/9.78G [02:43<01:35, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.91G/9.94G [02:48<01:52, 26.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  63% 6.17G/9.78G [02:48<02:21, 25.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  70% 6.98G/9.94G [02:49<01:30, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  64% 6.24G/9.78G [02:49<01:52, 31.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  65% 6.37G/9.78G [02:49<01:08, 50.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  71% 7.05G/9.94G [02:54<02:06, 22.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  72% 7.18G/9.94G [02:55<01:15, 36.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  66% 6.44G/9.78G [02:55<01:57, 28.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  73% 7.25G/9.94G [02:55<01:01, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  67% 6.57G/9.78G [03:00<01:57, 27.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  68% 6.64G/9.78G [03:01<01:33, 33.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.32G/9.94G [03:01<01:38, 26.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.71G/9.78G [03:06<02:13, 23.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  74% 7.38G/9.94G [03:06<02:06, 20.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  69% 6.77G/9.78G [03:08<01:54, 26.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  71% 6.91G/9.78G [03:13<01:45, 27.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  75% 7.45G/9.94G [03:13<02:35, 16.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  71% 6.97G/9.78G [03:14<01:32, 30.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  76% 7.52G/9.94G [03:17<02:26, 16.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  72% 7.04G/9.78G [03:17<01:36, 28.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  77% 7.65G/9.94G [03:17<01:20, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.72G/9.94G [03:18<01:04, 34.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.11G/9.78G [03:19<01:29, 30.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  78% 7.79G/9.94G [03:23<01:27, 24.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  73% 7.18G/9.78G [03:23<01:51, 23.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  74% 7.24G/9.78G [03:24<01:22, 30.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.92G/9.94G [03:24<00:52, 38.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  75% 7.38G/9.78G [03:29<01:25, 28.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.51G/9.78G [03:30<00:53, 42.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  80% 7.99G/9.94G [03:30<01:21, 24.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  77% 7.58G/9.78G [03:30<00:44, 49.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.12G/9.94G [03:31<00:51, 35.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  78% 7.65G/9.78G [03:35<01:12, 29.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  82% 8.19G/9.94G [03:36<01:05, 26.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  83% 8.25G/9.94G [03:36<00:52, 32.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  79% 7.71G/9.78G [03:37<01:01, 33.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  80% 7.85G/9.78G [03:38<00:40, 47.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  81% 7.91G/9.78G [03:39<00:35, 52.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  84% 8.32G/9.94G [03:39<00:51, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  82% 7.98G/9.78G [03:43<00:57, 31.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  85% 8.46G/9.94G [03:43<00:49, 30.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  82% 8.05G/9.78G [03:44<00:43, 40.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.52G/9.94G [03:47<00:53, 26.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  83% 8.11G/9.78G [03:47<00:55, 30.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  86% 8.59G/9.94G [03:48<00:41, 32.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.18G/9.78G [03:48<00:42, 38.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  84% 8.25G/9.78G [03:48<00:30, 49.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  87% 8.66G/9.94G [03:53<00:55, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  85% 8.32G/9.78G [03:53<00:50, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.72G/9.94G [03:54<00:41, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.38G/9.78G [03:54<00:37, 36.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  86% 8.45G/9.78G [03:54<00:27, 49.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  88% 8.79G/9.94G [03:54<00:32, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  89% 8.86G/9.94G [03:54<00:22, 48.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  87% 8.52G/9.78G [03:55<00:22, 55.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.58G/9.78G [03:55<00:16, 73.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  88% 8.65G/9.78G [03:55<00:12, 91.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  90% 8.93G/9.94G [03:56<00:19, 51.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  89% 8.72G/9.78G [03:56<00:10, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.01G/9.94G [03:56<00:13, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  90% 8.79G/9.78G [03:56<00:09, 103MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  91% 8.92G/9.78G [03:57<00:06, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.05G/9.78G [03:57<00:04, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  93% 9.12G/9.78G [03:58<00:03, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  94% 9.19G/9.78G [03:58<00:02, 217MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.25G/9.78G [03:58<00:02, 232MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  95% 9.31G/9.78G [03:58<00:02, 199MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  96% 9.38G/9.78G [03:59<00:01, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.45G/9.78G [03:59<00:01, 270MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  97% 9.51G/9.78G [03:59<00:01, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  91% 9.07G/9.94G [04:00<00:22, 39.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  98% 9.58G/9.78G [04:00<00:00, 202MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  92% 9.14G/9.94G [04:00<00:15, 50.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.65G/9.78G [04:01<00:01, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin:  99% 9.72G/9.78G [04:01<00:00, 130MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model-00002-of-00003.bin: 100% 9.78G/9.78G [04:02<00:00, 40.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.21G/9.94G [04:02<00:16, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  93% 9.27G/9.94G [04:02<00:11, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  94% 9.34G/9.94G [04:06<00:16, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  95% 9.47G/9.94G [04:06<00:07, 62.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  96% 9.54G/9.94G [04:06<00:05, 75.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.61G/9.94G [04:12<00:10, 31.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  97% 9.68G/9.94G [04:12<00:06, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  98% 9.74G/9.94G [04:12<00:03, 56.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.81G/9.94G [04:12<00:01, 73.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin:  99% 9.87G/9.94G [04:13<00:00, 91.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00003.bin: 100% 9.94G/9.94G [04:13<00:00, 39.2MB/s]\n",
            "Fetching 3 files: 100% 3/3 [04:14<00:00, 84.78s/it] \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Direct-Preference-Optimization/scripts/summarization/train_summary.py\", line 70, in <module>\n",
            "    main()\n",
            "  File \"/content/Direct-Preference-Optimization/scripts/summarization/train_summary.py\", line 28, in main\n",
            "    mb = load_models(model_name, dtype=dtype)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Direct-Preference-Optimization/src/dpo/models.py\", line 56, in load_models\n",
            "    policy_model = AutoModelForCausalLM.from_pretrained(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 5048, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 5432, in _load_pretrained_model\n",
            "    caching_allocator_warmup(model, expanded_device_map, hf_quantizer)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 6048, in caching_allocator_warmup\n",
            "    param: torch.device(device) for param, device in expanded_device_map.items() if is_accelerator_device(device)\n",
            "                                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 6022, in is_accelerator_device\n",
            "    return torch.device(device).type not in [\"meta\", \"cpu\"]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Cannot access accelerator device when none is available.\n"
          ]
        }
      ],
      "source": [
        "!python3 scripts/summarization/train_summary.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9goF9ZNV2K5T",
        "outputId": "d0147cc5-2643-4101-b657-290025385e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-02 07:20:31.639689: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-02 07:20:31.644566: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2026-01-02 07:20:31.660279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767338431.686607    2002 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767338431.693282    2002 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767338431.710624    2002 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338431.710670    2002 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338431.710675    2002 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767338431.710680    2002 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-02 07:20:31.715993: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "Using device: cpu\n",
            "Loading reference + policy models from: CarperAI/openai_summarize_tldr_sft\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Direct-Preference-Optimization/scripts/summarization/eval_summary.py\", line 256, in <module>\n",
            "    main()\n",
            "  File \"/content/Direct-Preference-Optimization/scripts/summarization/eval_summary.py\", line 136, in main\n",
            "    mb = load_models(ref_model_name, dtype=config[\"model\"][\"dtype\"])\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Direct-Preference-Optimization/src/dpo/models.py\", line 56, in load_models\n",
            "    policy_model = AutoModelForCausalLM.from_pretrained(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\", line 604, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 277, in _wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 5048, in from_pretrained\n",
            "    ) = cls._load_pretrained_model(\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 5432, in _load_pretrained_model\n",
            "    caching_allocator_warmup(model, expanded_device_map, hf_quantizer)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 6048, in caching_allocator_warmup\n",
            "    param: torch.device(device) for param, device in expanded_device_map.items() if is_accelerator_device(device)\n",
            "                                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\", line 6022, in is_accelerator_device\n",
            "    return torch.device(device).type not in [\"meta\", \"cpu\"]\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Cannot access accelerator device when none is available.\n"
          ]
        }
      ],
      "source": [
        "!python3 scripts/summarization/eval_summary.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
