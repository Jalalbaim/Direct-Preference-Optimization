{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958ee975",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b7f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation pour Colab (Python 3.12+)\n",
    "!pip install --upgrade pip setuptools wheel -q\n",
    "!pip install transformers[torch] datasets wandb accelerate -q\n",
    "\n",
    "# VÃ©rification\n",
    "import torch\n",
    "import transformers\n",
    "print(\"âœ… Installation rÃ©ussie!\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09e59c",
   "metadata": {},
   "source": [
    "## 0. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    SAVE_BASE_PATH = '/content/drive/MyDrive/dpo_ppo_training'\n",
    "    os.makedirs(SAVE_BASE_PATH, exist_ok=True)\n",
    "    print(f\"âœ… Google Drive montÃ©. ModÃ¨les sauvegardÃ©s sur: {SAVE_BASE_PATH}\")\n",
    "    USE_DRIVE = True\n",
    "except ImportError:\n",
    "    SAVE_BASE_PATH = './results'\n",
    "    USE_DRIVE = False\n",
    "    print(f\"âš ï¸  Pas de Google Drive dÃ©tectÃ©. Stockage local: {SAVE_BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a9373",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09deca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "# =====================================\n",
    "# CONFIGURATION\n",
    "# =====================================\n",
    "\n",
    "# Model choice\n",
    "BASE_MODEL = \"distilbert-base-uncased\"  # LÃ©ger et rapide (ou \"roberta-base\")\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "GRADIENT_ACCUMULATION_STEPS = 2\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# Paths\n",
    "REWARD_MODEL_PATH = f\"{SAVE_BASE_PATH}/reward_model\"\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Reward Model Training Configuration\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Base Model: {BASE_MODEL}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Gradient Accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"Effective Batch Size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Max Length: {MAX_LENGTH}\")\n",
    "print(f\"Output: {REWARD_MODEL_PATH}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b9afc8",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Dataset\n",
    "\n",
    "**StratÃ©gie** :\n",
    "- Chaque paire (prompt, chosen, rejected) â†’ 2 samples\n",
    "- Sample 1: (prompt + chosen, label=1)\n",
    "- Sample 2: (prompt + rejected, label=0)\n",
    "- Le modÃ¨le apprend : chosen > rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Ã‰TAPE 1: Chargement des paires de prÃ©fÃ©rences\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load preference pairs\n",
    "pairs_path = f\"{SAVE_BASE_PATH}/datasets/preference_pairs.json\"\n",
    "\n",
    "if not os.path.exists(pairs_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ Dataset introuvable: {pairs_path}\\n\"\n",
    "        \"Veuillez d'abord gÃ©nÃ©rer les paires de prÃ©fÃ©rences.\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸ“¥ Chargement depuis: {pairs_path}\")\n",
    "with open(pairs_path, 'r', encoding='utf-8') as f:\n",
    "    preference_pairs = json.load(f)\n",
    "\n",
    "print(f\"âœ… {len(preference_pairs)} paires chargÃ©es\")\n",
    "\n",
    "# Create binary classification dataset\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for pair in preference_pairs:\n",
    "    # Chosen example (label=1, positive class)\n",
    "    texts.append(pair[\"chosen\"])\n",
    "    labels.append(1)\n",
    "    \n",
    "    # Rejected example (label=0, negative class)\n",
    "    texts.append(pair[\"rejected\"])\n",
    "    labels.append(0)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset crÃ©Ã©:\")\n",
    "print(f\"   - Total samples: {len(texts)}\")\n",
    "print(f\"   - Chosen (label=1): {sum(labels)}\")\n",
    "print(f\"   - Rejected (label=0): {len(labels) - sum(labels)}\")\n",
    "\n",
    "# Create HuggingFace dataset\n",
    "reward_dataset = Dataset.from_dict({\n",
    "    \"text\": texts,\n",
    "    \"label\": labels\n",
    "})\n",
    "\n",
    "# Split train/validation\n",
    "split_dataset = reward_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "val_dataset = split_dataset[\"test\"]\n",
    "\n",
    "print(f\"\\nâœ… Train: {len(train_dataset)}, Validation: {len(val_dataset)}\")\n",
    "print(f\"\\nExemple de sample:\")\n",
    "print(f\"  Text: {train_dataset[0]['text'][:100]}...\")\n",
    "print(f\"  Label: {train_dataset[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e5746",
   "metadata": {},
   "source": [
    "## 3. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8327f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Ã‰TAPE 2: Chargement du modÃ¨le\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load tokenizer\n",
    "print(f\"\\nðŸ“¥ Chargement du tokenizer: {BASE_MODEL}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"âœ… Tokenizer chargÃ©\")\n",
    "\n",
    "# Load model for binary classification (num_labels=2: chosen vs rejected)\n",
    "print(f\"\\nðŸ“¥ Chargement du modÃ¨le: {BASE_MODEL}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    num_labels=2,  # Binary classification: chosen (1) vs rejected (0)\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    print(f\"âœ… ModÃ¨le chargÃ© sur GPU ({model.num_parameters() / 1e6:.1f}M params)\")\n",
    "else:\n",
    "    print(f\"âš ï¸  ModÃ¨le chargÃ© sur CPU\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… ModÃ¨le prÃªt pour l'entraÃ®nement\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb32349",
   "metadata": {},
   "source": [
    "## 4. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ccd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing dataset...\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=False  # Dynamic padding dans DataCollator\n",
    "    )\n",
    "\n",
    "# Tokenize\n",
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "tokenized_val = val_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "print(f\"âœ… Tokenization terminÃ©e\")\n",
    "print(f\"   Train samples: {len(tokenized_train)}\")\n",
    "print(f\"   Val samples: {len(tokenized_val)}\")\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24964c05",
   "metadata": {},
   "source": [
    "## 5. Initialize W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to W&B\n",
    "wandb.login()\n",
    "\n",
    "# Initialize W&B run\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_name = f\"reward_model_{timestamp}\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"reward_model\",\n",
    "    name=run_name,\n",
    "    config={\n",
    "        \"base_model\": BASE_MODEL,\n",
    "        \"num_pairs\": len(preference_pairs),\n",
    "        \"num_samples\": len(texts),\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"âœ… W&B initialized: {run_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be956a",
   "metadata": {},
   "source": [
    "## 6. Configure Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Ã‰TAPE 3: Configuration du Trainer\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=REWARD_MODEL_PATH,\n",
    "    \n",
    "    # Training\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    \n",
    "    # Saving\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    \n",
    "    # Optimization\n",
    "    fp16=False,\n",
    "    bf16=True if torch.cuda.is_available() else False,\n",
    "    \n",
    "    # Other\n",
    "    seed=42,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š Configuration:\")\n",
    "print(f\"   - Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   - Gradient accumulation: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"   - Effective batch: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"   - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   - Total steps: ~{len(tokenized_train) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS) * NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c170a",
   "metadata": {},
   "source": [
    "## 7. Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c88e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy, precision, recall, F1 for binary classification.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "print(\"âœ… Metrics function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2b1d5",
   "metadata": {},
   "source": [
    "## 8. Train Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Ã‰TAPE 4: EntraÃ®nement du Reward Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸš€ DÃ©marrage de l'entraÃ®nement...\\n\")\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… EntraÃ®nement terminÃ©!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdb65d",
   "metadata": {},
   "source": [
    "## 9. Evaluate Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Ã‰TAPE 5: Ã‰valuation finale\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"\\nðŸ“Š RÃ©sultats sur validation:\")\n",
    "for metric, value in eval_results.items():\n",
    "    print(f\"   {metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… Ã‰valuation terminÃ©e\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5765ac",
   "metadata": {},
   "source": [
    "## 10. Save Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Ã‰TAPE 6: Sauvegarde du modÃ¨le\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save model and tokenizer\n",
    "print(f\"\\nðŸ’¾ Sauvegarde dans: {REWARD_MODEL_PATH}\")\n",
    "trainer.save_model(REWARD_MODEL_PATH)\n",
    "tokenizer.save_pretrained(REWARD_MODEL_PATH)\n",
    "\n",
    "print(f\"\\nâœ… Reward model sauvegardÃ©!\")\n",
    "print(f\"\\nðŸ“ Fichiers crÃ©Ã©s:\")\n",
    "print(f\"   - {REWARD_MODEL_PATH}/pytorch_model.bin\")\n",
    "print(f\"   - {REWARD_MODEL_PATH}/config.json\")\n",
    "print(f\"   - {REWARD_MODEL_PATH}/tokenizer.json\")\n",
    "\n",
    "# Close W&B\n",
    "wandb.finish()\n",
    "print(f\"\\nâœ… W&B run closed\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"âœ… REWARD MODEL TRAINING COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nðŸŽ¯ Prochaine Ã©tape:\")\n",
    "print(f\"   Utilisez ce modÃ¨le pour PPO avec USE_REWARD_MODEL=True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc25bab",
   "metadata": {},
   "source": [
    "## 11. Test Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Test du Reward Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load model for testing\n",
    "test_model = AutoModelForSequenceClassification.from_pretrained(REWARD_MODEL_PATH)\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL_PATH)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    test_model = test_model.to(\"cuda\")\n",
    "\n",
    "test_model.eval()\n",
    "\n",
    "# Test texts\n",
    "test_texts = [\n",
    "    \"This movie is absolutely amazing and wonderful! I loved every minute of it.\",\n",
    "    \"This movie is terrible, boring and a complete waste of time. Awful!\",\n",
    "    \"The film was okay, nothing special but not bad either.\"\n",
    "]\n",
    "\n",
    "print(f\"\\nðŸ“Š PrÃ©dictions du reward model:\\n\")\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    # Tokenize\n",
    "    inputs = test_tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = test_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Probability of being \"chosen\" (class 1)\n",
    "        reward_score = probs[0, 1].item()\n",
    "        prediction = \"CHOSEN\" if reward_score > 0.5 else \"REJECTED\"\n",
    "    \n",
    "    print(f\"Text {i}: {text[:60]}...\")\n",
    "    print(f\"  â†’ Reward Score: {reward_score:.4f}\")\n",
    "    print(f\"  â†’ Prediction: {prediction}\")\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"âœ… Test terminÃ©!\")\n",
    "print(f\"\\nðŸ’¡ Le reward model est prÃªt Ã  Ãªtre utilisÃ© dans PPO\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
